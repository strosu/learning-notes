# Seven Databases in Seven Weeks

Contents
========

 * [Intro](#intro)
 * [PostreSQL](#postgres)
 * [HBase](#hbase)
 * [MongoDB](#mongo)
 * [CouchDB](#couchdb)
 * [Neo4J](#neo4j)

# Intro

- The goal is to get a better understanding of the types of tools available for data storage and manipulation. 
- Any database can be used to store any data, just like you can use a screwdriver to hammer a nail. Just because you can use them does not make them the right tools for the job
- By understanding what each type of database is best at, it allows us to build systems that are simpler and better aligned with the current requirements

For each of the databases presented, the book explores:
- What type of database is it? Relational, key-value, columnar, document-oriented or graph? Each category is generally better suited for a particular pattern of work
- Why was it created? The conditions which led to its creation need to be viewed as part of a larger context, in order to understand the problems it was meant to solve
- What makes it unique? Querying on arbitrary fields, indexing, ridigity of its schema, etc
- How does it perform? Does it support replication? Sharding? Is the data kept together, or is it distributed using consistent hashing? Is the database optimized for reads or writes? 
- How does it scale? More geared towards horizontal scaling (MongoDB, HBase, DynamoDB), or vertical (Postgres, Neo4J, Redis), or something in between? 


## Database types

### Relational

- two dimensional tables with rows and collumns
- interacton is done via SQL queries
- data values are typed and may be: numeric, strings, dates, blobs or others. These types are enforced by the system via the table schemas
- tables can be morphed into new ones via joining
- covered exampls is [PostreSQL](#postgres)

### Key Value

- simples model covered
- stores data similarly to a Dictionary
- some implementation allow defining more compelex types, or iterating through all the values, but not necessarily
- due to its simplicity, the performance can be great, but this won't be hepful with complex queries or aggregations
- covered examples: Redis, DynamoDB (TODO - link here)

Redis:
- supports complex data types like hashes and sorted sets (this is relevant for some scenarios, e.g. a learderboard can be stored out of the box).
- supports a publish-subscribe pattern, as well as blocking queues
- caches writes in memory before pushing to disk; very performant, but can lead to data loss
- great as a message broker and for holding noncritical information (if it's lost, it can be reconstructued or discarded safely). E.g. session data, worst case scenario some users need to log in again

### Columnar

- values in the same column are stored together, helping with data locallity for certain queries
- adding columns is inexpensive and is done on a row by row basis
- each row can have a different set of columns and null values are not stored, so sparse databases don't take up so much space
- covered examples: [HBase](#hbase)

### Document

- stores documents: objects with a unque ID, and more fields, which can also be documents
- supports nested structures
- covered: [MongoDB](#mongodb) and [CouchDB](#couchDB)

### Graph 

- suited for representing relations between highly connected data points
- database consists of nodes and the edges between them
- easy to traverse through nodes by following the relations
- covered: [Neo4J](#neo4j)


# Postgres

## Properties

- has a well defined set of strictly enforced columns, that all rows must adhere to
- the enforcement is done at insertion time, like a staticly typed language

- A table (relation) is a set of rows (tuples), containing columns(attributes) mapped to atomic values. 
- The available attributes are defined at a table level. The header maps each attribute to a constraining type 

- easy to store data and figure out what to do with it later; the entire query model can change
- data safety via ACID compliance:
    - Atomicity - an entire operation will either succeed or fail, with no partial results; e.g. if our transaction modifies two rows in two tables, they will either be both altered, or none
    - Consistency - an operation can only move the database from one valid state to another valid state;
        - All the writte data must comply with all the database's constraints
    - Isolation - although operations are happening concurrently, isolation makes it appear as they happened serially. 
        - It prevents things like dirty-reads (when an operation observes another that is halfway through)
        - TODO: add more information on concurrency control 
    - Durability

# Hbase

# MongoDB

- document data store - the entire row is saves as a JSON, so a list of key-values pairs (including nested ones)
- IDs are autogenerated for each row
- we can construct queries based on the information in any of the attributes
- most of the query code is executed server-side, similarly to stored procedures in SQL

A collection of *documents* results in a *table*. 

Creating a new row:

```
> db.towns.insert({
name: "New York",
population: 22200000,
lastCensus: ISODate("2016-07-01"),
famousFor: [ "the MOMA", "food", "Derek Jeter" ],
mayor : {
name : "Bill de Blasio",
party : "D"
}
})
```

Querying examples:

```
> db.towns.find({ "_id" : ObjectId("59094288afbc9350ada6b807") })
{
"_id" : ObjectId("59094288afbc9350ada6b807"),
"name" : "Punxsutawney",
"population" : 6200,
"lastCensus" : ISODate("2016-01-31T00:00:00Z"),
"famousFor" : [ "Punxsutawney Phil" ],
"mayor" : { "name" : "Richard Alexander" }
}
```

Querying inside the nested values:

```
> db.towns.find(
{ famousFor : /moma/ },
{ _id : 0, name : 1, famousFor : 1 }
)
{ "name" : "New York", "famousFor" : [ "the MOMA", "food" ] }
```

```
> db.towns.find(
{ 'mayor.party' : { $exists : false } },
{ _id : 0, name : 1, mayor : 1 }
)
{ "name" : "Punxsutawney", "mayor" : { "name" : "Richard Alexander" } }
```

Indexing is supported via B-tree indexes (storing the ID of the first page block). These are supported on **ANY** attibute, including nested ones. 

## Distributed Mongo

- collections are sharded and replicated across multiple machines
- uses single leader replication withing a replica set
- the master node is the only one that accepts **writes AND reads**, the other nodes are there for replication purposes
- a write is successful only when the majority of nodes have a copy of it (similarly to Raft)
- provides strong consistency on reads

## Pros

- handles large amounts of data by scaling horizontally and replicating between instances
- very flexible data model

## Cons

- no schema is enforced
- no static typing - typos can screw things up easily

# CouchDB

- document oriented, append-only log DB
- every document has a unique readonly ID, that is either provided at creation, or auto generated
- additionally, each document has a version (_rev). A document is uniquely identified by the ID and Rev. 
- no transactions, no locking
- data is immutable, the entire document needs to be passed on update operations
- concurrent operations are first-come first served, but only one can succeed; the second one will mismatch the version
- this applies to operations arriving concurrently on the same node, see [Replication](#replication) for concurrent conflicting updates on different nodes

Querying:
- by ID and optionally Rev
- more complex queries need to be implemented as a MapReduce. They are called Views and are saved as documents
- Views can consist of mappers (where a row can just emit a value if it matches), or both mapper and reducers

## ChangeAPi

By being implemented as an append log, CouchDB supports exporting its stream of changes.
Supports:
- polling: the client also sends an offset of the last seen change
- long polling: CouchDB will respond with data on the socket when it has it; afterwards you need to initiate a new connection
- websockets

If we don't want to get notified for any change, these can be filtered 

## Replication

- Implemented as multiple leader replication: multiple instances can accept write requests and we need to reconcile them.
- Reconciliation is done automatically by the DB, by picking a winner and loser. This is guaranteed to be consistent across all nodes
- when querying for a document, it can also return the conflicting versions. It is up to the application code to decide what to do with these

# Neo4J

# DynamoDB

# Redis